{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T06:53:26.876724Z",
     "start_time": "2025-12-19T06:53:24.948003Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import Tuple\n",
    "\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "DATA_JSON_PATH = \"data/archive (1)/VQA_RAD Dataset Public.json\"\n",
    "DATA_IMAGE_DIR = \"data/archive (1)/VQA_RAD Image Folder\"\n",
    "\n",
    "\n",
    "def normalize_answer(ans: str) -> str:\n",
    "    \"\"\"简单归一化答案，用于区分close(是/否)和open类型。\n",
    "\n",
    "    - 先 lower + 去空格\n",
    "    - 去掉句末标点\n",
    "    - 规范 \"yes\" / \"no\" 写法\n",
    "    - 对部分 open 答案做同义词合并（如 right side -> right）\n",
    "    \"\"\"\n",
    "    if ans is None:\n",
    "        return \"\"\n",
    "    ans = str(ans).lower().strip()\n",
    "    ans_clean = ans.rstrip('.,!?;:').strip()\n",
    "\n",
    "    # 先规范 yes/no\n",
    "    if ans_clean == \"yes\":\n",
    "        return \"yes\"\n",
    "    if ans_clean == \"no\":\n",
    "        return \"no\"\n",
    "\n",
    "    if ans_clean.startswith(\"yes\"):\n",
    "        if len(ans_clean) == 3 or ans_clean[3] in [\" \", \",\", \".\", \"!\", \"?\", \";\", \":\"]:\n",
    "            return \"yes\"\n",
    "    if ans_clean.startswith(\"no\"):\n",
    "        if len(ans_clean) == 2 or ans_clean[2] in [\" \", \",\", \".\", \"!\", \"?\", \";\", \":\"]:\n",
    "            return \"no\"\n",
    "\n",
    "    # 针对 open 问题的一些简单同义合并\n",
    "    synonym_map = {\n",
    "        \"right side\": \"right\",\n",
    "        \"left side\": \"left\",\n",
    "        \"rt\": \"right\",\n",
    "        \"lt\": \"left\",\n",
    "        \"xray\": \"x-ray\",\n",
    "        \"x ray\": \"x-ray\",\n",
    "        \"ct scan\": \"ct\",\n",
    "    }\n",
    "    if ans_clean in synonym_map:\n",
    "        return synonym_map[ans_clean]\n",
    "    \n",
    "    # 处理包含 \"xray\" 或 \"x-ray\" 的答案（如 \"chest xray\" -> \"x-ray\"）\n",
    "    # 将 \"xray\" 替换为 \"x-ray\" 以便统一匹配\n",
    "    ans_clean = ans_clean.replace(\"xray\", \"x-ray\").replace(\"x ray\", \"x-ray\")\n",
    "    # 如果答案以 \"x-ray\" 结尾或包含 \"x-ray\"，且问题是问图像类型，可以归一化为 \"x-ray\"\n",
    "    # 但这里我们只做简单的替换，保留原始信息\n",
    "    \n",
    "    return ans_clean\n",
    "\n",
    "\n",
    "class VQARADBaselineDataset(Dataset):\n",
    "    \"\"\"基础 VQA-RAD 数据集类，只负责读图像/文本/答案。\n",
    "\n",
    "    之后我们会在此之上构建不同模型（CNN baseline, Transformer 等）。\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, json_path: str = DATA_JSON_PATH, image_dir: str = DATA_IMAGE_DIR,\n",
    "                 transform=None):\n",
    "        assert os.path.exists(json_path), f\"JSON 文件不存在: {json_path}\"\n",
    "        assert os.path.exists(image_dir), f\"图像目录不存在: {image_dir}\"\n",
    "\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            self.data = json.load(f)\n",
    "\n",
    "        self.image_dir = image_dir\n",
    "        # 图像增强 + 标准化：有助于减轻过拟合\n",
    "        self.transform = transform or transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def _get_image_path(self, item) -> str:\n",
    "        # 兼容 \"image\" / \"image_name\" 两种字段\n",
    "        image_key = \"image\" if \"image\" in item else \"image_name\"\n",
    "        return os.path.join(self.image_dir, item[image_key])\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, str, str, str]:\n",
    "        \"\"\"返回: (image, question, answer, q_type)\n",
    "\n",
    "        - q_type: \"close\" 表示是/否题; \"open\" 表示开放式问题\n",
    "        \"\"\"\n",
    "        item = self.data[idx]\n",
    "        img_path = self._get_image_path(item)\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        question = item[\"question\"]\n",
    "        answer_raw = item.get(\"answer\", \"\")\n",
    "        ans_norm = normalize_answer(answer_raw)\n",
    "        q_type = \"close\" if ans_norm in [\"yes\", \"no\"] else \"open\"\n",
    "\n",
    "        return image, question, str(answer_raw), q_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1facb1f359167418",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T06:53:34.862656Z",
     "start_time": "2025-12-19T06:53:26.881705Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集总样本数: 2248\n",
      "Close (是/否) 样本数: 1193\n",
      "Open  (开放式) 样本数: 1055\n",
      "\n",
      "DataLoader 已创建:\n",
      "  close_loader: batch_size=32, steps/epoch≈38\n",
      "  open_loader : batch_size=32, steps/epoch≈33\n",
      "词表大小: 1227, MAX_Q_LEN = 20\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "# 1. 加载完整数据集\n",
    "full_dataset = VQARADBaselineDataset(\n",
    "    json_path=DATA_JSON_PATH,\n",
    "    image_dir=DATA_IMAGE_DIR,\n",
    ")\n",
    "\n",
    "print(f\"数据集总样本数: {len(full_dataset)}\")\n",
    "\n",
    "# 2. 根据答案把样本划分为 close (yes/no) 和 open\n",
    "close_indices = []\n",
    "open_indices = []\n",
    "\n",
    "for idx in range(len(full_dataset)):\n",
    "    _, _, ans_raw, q_type = full_dataset[idx]\n",
    "    if q_type == \"close\":\n",
    "        close_indices.append(idx)\n",
    "    else:\n",
    "        open_indices.append(idx)\n",
    "\n",
    "print(f\"Close (是/否) 样本数: {len(close_indices)}\")\n",
    "print(f\"Open  (开放式) 样本数: {len(open_indices)}\")\n",
    "\n",
    "# 3. 构造两个子数据集，后面可以分别训练/评估\n",
    "close_dataset = Subset(full_dataset, close_indices)\n",
    "open_dataset = Subset(full_dataset, open_indices)\n",
    "\n",
    "# 4. 先准备好 DataLoader，后面直接接模型即可\n",
    "batch_size = 32\n",
    "\n",
    "close_loader = DataLoader(close_dataset, batch_size=batch_size, shuffle=True)\n",
    "open_loader = DataLoader(open_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(\"\\nDataLoader 已创建:\")\n",
    "print(f\"  close_loader: batch_size={batch_size}, steps/epoch≈{len(close_loader)}\")\n",
    "print(f\"  open_loader : batch_size={batch_size}, steps/epoch≈{len(open_loader)}\")\n",
    "\n",
    "# 5. 基于所有 question 构建简单词表，用于文本 Transformer\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def tokenize(text: str):\n",
    "    text = str(text).lower().strip()\n",
    "    # 简单按空格切分即可；医学术语也能基本覆盖\n",
    "    return text.replace(\"?\", \" \").replace(\",\", \" \").split()\n",
    "\n",
    "\n",
    "counter = Counter()\n",
    "for item in full_dataset.data:\n",
    "    q = item.get(\"question\", \"\")\n",
    "    tokens = tokenize(q)\n",
    "    counter.update(tokens)\n",
    "\n",
    "# 特殊符号\n",
    "word2idx = {\"<pad>\": 0, \"<unk>\": 1}\n",
    "for w, c in counter.items():\n",
    "    # 过滤特别少见的词可以稍微减小词表，这里阈值设为 1 就是全收\n",
    "    if w not in word2idx and c >= 1:\n",
    "        word2idx[w] = len(word2idx)\n",
    "\n",
    "idx2word = {i: w for w, i in word2idx.items()}\n",
    "MAX_Q_LEN = 20  # 问题一般比较短，20 足够覆盖大部分\n",
    "\n",
    "print(f\"词表大小: {len(word2idx)}, MAX_Q_LEN = {MAX_Q_LEN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2c8ab6f8d53695",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T06:53:43.855540Z",
     "start_time": "2025-12-19T06:53:34.867260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集总样本数: 2248\n",
      "Close (是/否) 样本数: 1193\n",
      "Open  (开放式) 样本数: 1055\n",
      "\n",
      "Close (yes/no) 数据集划分:\n",
      "  训练集: 954 个样本 (80.0%)\n",
      "  测试集: 239 个样本 (20.0%)\n",
      "\n",
      "Open 数据集划分:\n",
      "  训练集: 844 个样本 (80.0%)\n",
      "  测试集: 211 个样本 (20.0%)\n",
      "\n",
      "DataLoader 已创建:\n",
      "  close_train_loader: 30 batches, 954 samples\n",
      "  close_test_loader: 8 batches, 239 samples\n",
      "  open_train_loader: 27 batches, 844 samples\n",
      "  open_test_loader: 7 batches, 211 samples\n",
      "\n",
      "词表大小: 1227, MAX_Q_LEN = 20\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Subset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import random\n",
    "# 设置随机种子以确保结果可复现\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# 1. 加载完整数据集\n",
    "full_dataset = VQARADBaselineDataset(\n",
    "    json_path=DATA_JSON_PATH,\n",
    "    image_dir=DATA_IMAGE_DIR,\n",
    ")\n",
    "\n",
    "print(f\"数据集总样本数: {len(full_dataset)}\")\n",
    "\n",
    "# 2. 根据答案把样本划分为 close (yes/no) 和 open\n",
    "close_indices = []\n",
    "open_indices = []\n",
    "\n",
    "for idx in range(len(full_dataset)):\n",
    "    _, _, ans_raw, q_type = full_dataset[idx]\n",
    "    if q_type == \"close\":\n",
    "        close_indices.append(idx)\n",
    "    else:\n",
    "        open_indices.append(idx)\n",
    "\n",
    "print(f\"Close (是/否) 样本数: {len(close_indices)}\")\n",
    "print(f\"Open  (开放式) 样本数: {len(open_indices)}\")\n",
    "\n",
    "# 3. 对close和open数据集分别进行8:2的划分（训练集:测试集）\n",
    "# 3.1 划分close数据集\n",
    "close_train_idx, close_test_idx = train_test_split(\n",
    "    close_indices, \n",
    "    test_size=0.2,  # 20% 作为测试集\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# 3.2 划分open数据集\n",
    "open_train_idx, open_test_idx = train_test_split(\n",
    "    open_indices,\n",
    "    test_size=0.2,  # 20% 作为测试集\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(\"\\nClose (yes/no) 数据集划分:\")\n",
    "print(f\"  训练集: {len(close_train_idx)} 个样本 ({len(close_train_idx)/len(close_indices)*100:.1f}%)\")\n",
    "print(f\"  测试集: {len(close_test_idx)} 个样本 ({len(close_test_idx)/len(close_indices)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nOpen 数据集划分:\")\n",
    "print(f\"  训练集: {len(open_train_idx)} 个样本 ({len(open_train_idx)/len(open_indices)*100:.1f}%)\")\n",
    "print(f\"  测试集: {len(open_test_idx)} 个样本 ({len(open_test_idx)/len(open_indices)*100:.1f}%)\")\n",
    "\n",
    "# 4. 创建数据集子集\n",
    "close_train_dataset = Subset(full_dataset, close_train_idx)\n",
    "close_test_dataset = Subset(full_dataset, close_test_idx)\n",
    "\n",
    "open_train_dataset = Subset(full_dataset, open_train_idx)\n",
    "open_test_dataset = Subset(full_dataset, open_test_idx)\n",
    "\n",
    "# 5. 创建DataLoader\n",
    "batch_size = 32\n",
    "\n",
    "close_train_loader = DataLoader(close_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "close_test_loader = DataLoader(close_test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "open_train_loader = DataLoader(open_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "open_test_loader = DataLoader(open_test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"\\nDataLoader 已创建:\")\n",
    "print(f\"  close_train_loader: {len(close_train_loader)} batches, {len(close_train_dataset)} samples\")\n",
    "print(f\"  close_test_loader: {len(close_test_loader)} batches, {len(close_test_dataset)} samples\")\n",
    "print(f\"  open_train_loader: {len(open_train_loader)} batches, {len(open_train_dataset)} samples\")\n",
    "print(f\"  open_test_loader: {len(open_test_loader)} batches, {len(open_test_dataset)} samples\")\n",
    "\n",
    "# 6. 基于所有 question 构建简单词表，用于文本 Transformer\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def tokenize(text: str):\n",
    "    text = str(text).lower().strip()\n",
    "    # 简单按空格切分即可；医学术语也能基本覆盖\n",
    "    return text.replace(\"?\", \" \").replace(\",\", \" \").split()\n",
    "\n",
    "\n",
    "counter = Counter()\n",
    "for item in full_dataset.data:\n",
    "    q = item.get(\"question\", \"\")\n",
    "    tokens = tokenize(q)\n",
    "    counter.update(tokens)\n",
    "\n",
    "# 特殊符号\n",
    "word2idx = {\"<pad>\": 0, \"<unk>\": 1}\n",
    "for w, c in counter.items():\n",
    "    # 过滤特别少见的词可以稍微减小词表，这里阈值设为 1 就是全收\n",
    "    if w not in word2idx and c >= 1:\n",
    "        word2idx[w] = len(word2idx)\n",
    "\n",
    "idx2word = {i: w for w, i in word2idx.items()}\n",
    "MAX_Q_LEN = 20  # 问题一般比较短，20 足够覆盖大部分\n",
    "\n",
    "print(f\"\\n词表大小: {len(word2idx)}, MAX_Q_LEN = {MAX_Q_LEN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5a8ccc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T06:53:51.031423Z",
     "start_time": "2025-12-19T06:53:43.860912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\76949\\miniconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n",
      "BLIP 模型与 Processor 已加载。\n"
     ]
    }
   ],
   "source": [
    "# ==== 使用 BLIP 在 close (yes/no) 子集上进行微调 ====\n",
    "\n",
    "%pip install -q transformers accelerate\n",
    "\n",
    "import torch\n",
    "from transformers import BlipProcessor, BlipForQuestionAnswering\n",
    "\n",
    "# 设备配置\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"使用设备:\", device)\n",
    "\n",
    "# 加载预训练 BLIP VQA 模型与 Processor\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\n",
    "model = BlipForQuestionAnswering.from_pretrained(\"Salesforce/blip-vqa-base\").to(device)\n",
    "\n",
    "print(\"BLIP 模型与 Processor 已加载。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4469cf16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T06:56:33.916669Z",
     "start_time": "2025-12-19T06:53:51.035829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLIP close 训练集大小: 954，steps/epoch≈120\n",
      "BLIP close 测试集大小: 239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4: 100%|██████████| 120/120 [00:40<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 4, 平均 loss = 0.3572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4: 100%|██████████| 120/120 [00:40<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 / 4, 平均 loss = 0.3115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4: 100%|██████████| 120/120 [00:40<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 / 4, 平均 loss = 0.2456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4: 100%|██████████| 120/120 [00:40<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 / 4, 平均 loss = 0.1892\n",
      "BLIP close(yes/no) 微调完成，模型已保存到: best_blip_close_yesno.pth\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from typing import List, Tuple\n",
    "\n",
    "# 构建一个专门给 BLIP 用的 close(yes/no) 数据集\n",
    "class VQARADBLIPCloseDataset(Dataset):\n",
    "    \"\"\"基于 full_dataset 和 close_indices，返回 (PIL image, question, answer_norm)。\"\"\"\n",
    "\n",
    "    def __init__(self, base_dataset: VQARADBaselineDataset, close_indices: List[int]):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.close_indices = close_indices\n",
    "        self.image_dir = base_dataset.image_dir\n",
    "        self.raw_items = base_dataset.data\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.close_indices)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[Image.Image, str, str]:\n",
    "        real_idx = self.close_indices[idx]\n",
    "        item = self.raw_items[real_idx]\n",
    "\n",
    "        # 读取原始图像（不做 torchvision 的增强，让 BLIP 自己处理）\n",
    "        image_path = self.base_dataset._get_image_path(item)\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        question = item.get(\"question\", \"\")\n",
    "        ans_raw = item.get(\"answer\", \"\")\n",
    "        ans_norm = normalize_answer(ans_raw)\n",
    "\n",
    "        # 理论上 close_indices 里已经是 yes/no，这里再保险判断一下\n",
    "        if ans_norm not in [\"yes\", \"no\"]:\n",
    "            # 如果极个别出现其他值，则强制转成 \"no\"（避免 tokenizer 出现太多无关 token）\n",
    "            ans_norm = \"no\"\n",
    "\n",
    "        return image, question, ans_norm\n",
    "\n",
    "\n",
    "def blip_collate_fn(batch):\n",
    "    \"\"\"将 (image, question, answer) 列表打包成 BLIP 可直接输入的 batch。\"\"\"\n",
    "    images, questions, answers = zip(*batch)\n",
    "\n",
    "    # 使用 Processor 进行图像和文本的联合编码\n",
    "    inputs = processor(\n",
    "        images=list(images),\n",
    "        text=list(questions),\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    # 将答案也转成文本 token，作为 labels\n",
    "    label_tokens = processor.tokenizer(\n",
    "        list(answers),\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    inputs[\"labels\"] = label_tokens.input_ids\n",
    "\n",
    "    return inputs\n",
    "\n",
    "\n",
    "# 基于划分后的 close_train_idx 和 close_test_idx 构建 BLIP 训练用 DataLoader\n",
    "blip_close_train_dataset = VQARADBLIPCloseDataset(full_dataset, close_train_idx)\n",
    "blip_close_test_dataset = VQARADBLIPCloseDataset(full_dataset, close_test_idx)\n",
    "\n",
    "blip_batch_size = 8  # BLIP 模型较大，batch 不宜太大\n",
    "blip_close_train_loader = DataLoader(\n",
    "    blip_close_train_dataset,\n",
    "    batch_size=blip_batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=blip_collate_fn,\n",
    ")\n",
    "blip_close_test_loader = DataLoader(\n",
    "    blip_close_test_dataset,\n",
    "    batch_size=blip_batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=blip_collate_fn,\n",
    ")\n",
    "\n",
    "print(f\"BLIP close 训练集大小: {len(blip_close_train_dataset)}，steps/epoch≈{len(blip_close_train_loader)}\")\n",
    "print(f\"BLIP close 测试集大小: {len(blip_close_test_dataset)}\")\n",
    "\n",
    "\n",
    "# ==== 简单的 BLIP 微调训练循环（针对 yes/no） ====\n",
    "from torch.optim import AdamW\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "num_epochs = 4\n",
    "lr = 5e-5\n",
    "optimizer = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for batch in tqdm(blip_close_train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        # 将 batch 移动到 device 上\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_loss = epoch_loss / max(1, len(blip_close_train_loader))\n",
    "    print(f\"Epoch {epoch+1} / {num_epochs}, 平均 loss = {avg_loss:.4f}\")\n",
    "\n",
    "# 训练完成后保存权重\n",
    "save_path = \"best_blip_close_yesno.pth\"\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"BLIP close(yes/no) 微调完成，模型已保存到: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cde5c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T06:59:21.339467Z",
     "start_time": "2025-12-19T06:59:16.013607Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluate on the test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 30/30 [00:04<00:00,  6.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "前 10 个样本的预测结果对比:\n",
      "================================================================================\n",
      "\n",
      "[样本 1] ✗ 错误\n",
      "  问题: Are the patients' ribs symmetric on both sides?\n",
      "  真实答案: no (归一化: no)\n",
      "  预测答案: yes (归一化: yes)\n",
      "\n",
      "[样本 2] ✗ 错误\n",
      "  问题: Are there cilia present at the level of alveoli?\n",
      "  真实答案: no (归一化: no)\n",
      "  预测答案: yes (归一化: yes)\n",
      "\n",
      "[样本 3] ✗ 错误\n",
      "  问题: Is this coronal plane?\n",
      "  真实答案: yes (归一化: yes)\n",
      "  预测答案: no (归一化: no)\n",
      "\n",
      "[样本 4] ✗ 错误\n",
      "  问题: Is the patient lying down?\n",
      "  真实答案: yes (归一化: yes)\n",
      "  预测答案: no (归一化: no)\n",
      "\n",
      "[样本 5] ✓ 正确\n",
      "  问题: Do you see a cavitary lesion in this chest xray?\n",
      "  真实答案: yes (归一化: yes)\n",
      "  预测答案: yes (归一化: yes)\n",
      "\n",
      "[样本 6] ✓ 正确\n",
      "  问题: Is there free air under the diaphragm?\n",
      "  真实答案: no (归一化: no)\n",
      "  预测答案: no (归一化: no)\n",
      "\n",
      "[样本 7] ✓ 正确\n",
      "  问题: is there tracheal deviation?\n",
      "  真实答案: no (归一化: no)\n",
      "  预测答案: no (归一化: no)\n",
      "\n",
      "[样本 8] ✓ 正确\n",
      "  问题: Is this in the lumbar vertebral level?\n",
      "  真实答案: yes (归一化: yes)\n",
      "  预测答案: yes (归一化: yes)\n",
      "\n",
      "[样本 9] ✓ 正确\n",
      "  问题: Does this patient have a pneumothorax?\n",
      "  真实答案: no (归一化: no)\n",
      "  预测答案: no (归一化: no)\n",
      "\n",
      "[样本 10] ✓ 正确\n",
      "  问题: Was this patient given IV contrast?\n",
      "  真实答案: yes (归一化: yes)\n",
      "  预测答案: yes (归一化: yes)\n",
      "\n",
      "================================================================================\n",
      "后 10 个样本的预测结果对比:\n",
      "================================================================================\n",
      "\n",
      "[Sample 230] ✓ Right\n",
      "  Question: Is the appendix seen in this image inflamed?\n",
      "  Real answer: yes (Normalization: yes)\n",
      "  Predicted answer: yes (Normalization: yes)\n",
      "\n",
      "[Sample 231] ✗ Fault\n",
      "  Question: Are the lateral ventricles compressed?\n",
      "  Real answer: yes (Normalization: yes)\n",
      "  Predicted answer: no (Normalization: no)\n",
      "\n",
      "[Sample 232] ✗ Fault\n",
      "  Question: Are there rib fractures present?\n",
      "  Real answer: no (Normalization: no)\n",
      "  Predicted answer: yes (Normalization: yes)\n",
      "\n",
      "[Sample 233] ✓ Right\n",
      "  Question: Is there air trapped in the body?\n",
      "  Real answer: no (Normalization: no)\n",
      "  Predicted answer: no (Normalization: no)\n",
      "\n",
      "[Sample 234] ✓ Right\n",
      "  Question: Is there blurring of the grey-white matter junctions in the right temporal lobe?\n",
      "  Real answer: yes (Normalization: yes)\n",
      "  Predicted answer: yes (Normalization: yes)\n",
      "\n",
      "[Sample 235] ✗ Fault\n",
      "  Question: Is the diaphragm flat on either side?\n",
      "  Real answer: no (Normalization: no)\n",
      "  Predicted answer: yes (Normalization: yes)\n",
      "\n",
      "[Sample 236] ✓ Right\n",
      "  Question: Is there evidence of cytotoxic edema in the right temporal lobe?\n",
      "  Real answer: yes (Normalization: yes)\n",
      "  Predicted answer: yes (Normalization: yes)\n",
      "\n",
      "[Sample 237] ✓ Right\n",
      "  Question: Is this the axial plane?\n",
      "  Real answer: yes (Normalization: yes)\n",
      "  Predicted answer: yes (Normalization: yes)\n",
      "\n",
      "[Sample 238] ✓ Right\n",
      "  Question: Can the white and gray matter be differentiated?\n",
      "  Real answer: yes (Normalization: yes)\n",
      "  Predicted answer: yes (Normalization: yes)\n",
      "\n",
      "[Sample 239] ✓ Right\n",
      "  Question: Is this image abnormal?\n",
      "  Real answer: yes (Normalization: yes)\n",
      "  Predicted answer: yes (Normalization: yes)\n",
      "================================================================================\n",
      "Test accuracy: 70.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==== 在 close(yes/no) 测试集上评估 BLIP 准确率 ====\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# 自定义 collate_fn，保持 PIL.Image / 文本原样，避免默认拼成 tensor\n",
    "def eval_collate_fn(batch):\n",
    "    images, questions, answers = zip(*batch)  # tuple of length batch_size\n",
    "    return list(images), list(questions), list(answers)\n",
    "\n",
    "# 在测试集上评估\n",
    "eval_test_loader = DataLoader(\n",
    "    blip_close_test_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    collate_fn=eval_collate_fn,\n",
    ")\n",
    "\n",
    "def is_semantically_similar(pred: str, gt: str) -> bool:\n",
    "    \"\"\"\n",
    "    宽松的语义相似度判断函数\n",
    "    只要预测答案和真实答案在语义上相似，就返回True\n",
    "    \"\"\"\n",
    "    pred = pred.lower().strip()\n",
    "    gt = gt.lower().strip()\n",
    "    \n",
    "    # 1. 完全匹配\n",
    "    if pred == gt:\n",
    "        return True\n",
    "    \n",
    "    # 2. 去除标点符号后比较\n",
    "    pred_clean = re.sub(r'[^\\w\\s]', '', pred)\n",
    "    gt_clean = re.sub(r'[^\\w\\s]', '', gt)\n",
    "    if pred_clean == gt_clean:\n",
    "        return True\n",
    "    \n",
    "    # 3. 一方包含另一方（子串匹配）\n",
    "    if gt in pred or pred in gt:\n",
    "        return True\n",
    "    \n",
    "    # 4. 提取关键词进行比较（单词级别）\n",
    "    pred_words = set(re.findall(r'\\b\\w+\\b', pred))\n",
    "    gt_words = set(re.findall(r'\\b\\w+\\b', gt))\n",
    "    \n",
    "    # 移除停用词\n",
    "    stop_words = {'the', 'a', 'an', 'is', 'are', 'was', 'were', 'this', 'that', 'these', 'those'}\n",
    "    pred_words = pred_words - stop_words\n",
    "    gt_words = gt_words - stop_words\n",
    "    \n",
    "    # 计算单词重叠度\n",
    "    if len(gt_words) > 0:\n",
    "        overlap_ratio = len(pred_words & gt_words) / len(gt_words)\n",
    "        # 如果重叠度超过50%，认为语义相似\n",
    "        if overlap_ratio >= 0.5:\n",
    "            return True\n",
    "    \n",
    "    # 5. 处理常见的同义词和变体\n",
    "    synonyms = {\n",
    "        'x-ray': ['xray', 'x ray', 'chest xray', 'chest x-ray', 'xray image'],\n",
    "        'xray': ['x-ray', 'x ray', 'chest xray', 'chest x-ray'],\n",
    "        'ct': ['ct scan', 'computed tomography'],\n",
    "        'mri': ['magnetic resonance imaging'],\n",
    "        'intestines': ['small intestines', 'bowel', 'small bowel'],\n",
    "        'left': ['lt', 'left side'],\n",
    "        'right': ['rt', 'right side'],\n",
    "    }\n",
    "    \n",
    "    # 检查同义词\n",
    "    for key, variants in synonyms.items():\n",
    "        if key in gt and any(v in pred for v in variants):\n",
    "            return True\n",
    "        if key in pred and any(v in gt for v in variants):\n",
    "            return True\n",
    "    \n",
    "    # 6. 处理数字和单位（如 \"5cm\" vs \"5 cm\"）\n",
    "    pred_nums = set(re.findall(r'\\d+', pred))\n",
    "    gt_nums = set(re.findall(r'\\d+', gt))\n",
    "    if pred_nums == gt_nums and len(pred_nums) > 0:\n",
    "        # 如果数字相同，且其他单词有重叠，认为相似\n",
    "        pred_non_num_words = set(re.findall(r'\\b[a-z]+\\b', pred))\n",
    "        gt_non_num_words = set(re.findall(r'\\b[a-z]+\\b', gt))\n",
    "        if len(pred_non_num_words & gt_non_num_words) > 0:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def evaluate_accuracy(model, data_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # 存储所有结果用于打印\n",
    "    all_results = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, questions, answers in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            # 准备模型输入\n",
    "            inputs = processor(\n",
    "                images=images,\n",
    "                text=questions,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "            ).to(device)\n",
    "            \n",
    "            # 生成预测\n",
    "            outputs = model.generate(\n",
    "                input_ids=inputs[\"input_ids\"],\n",
    "                pixel_values=inputs[\"pixel_values\"],\n",
    "                attention_mask=inputs[\"attention_mask\"],\n",
    "                max_length=10,\n",
    "            )\n",
    "            \n",
    "            # 解码预测结果\n",
    "            preds = processor.batch_decode(outputs, skip_special_tokens=True)\n",
    "            \n",
    "            # 计算准确率并保存结果（使用宽松的语义匹配）\n",
    "            for pred_raw, true_ans_raw, question in zip(preds, answers, questions):\n",
    "                pred = normalize_answer(pred_raw)\n",
    "                true_ans = normalize_answer(true_ans_raw)\n",
    "                \n",
    "                # 使用宽松的语义匹配\n",
    "                is_correct = is_semantically_similar(pred, true_ans)\n",
    "                \n",
    "                if is_correct:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "                \n",
    "                # 保存结果\n",
    "                all_results.append({\n",
    "                    \"question\": question,\n",
    "                    \"pred_raw\": pred_raw,\n",
    "                    \"pred_norm\": pred,\n",
    "                    \"true_ans_raw\": true_ans_raw,\n",
    "                    \"true_ans_norm\": true_ans,\n",
    "                    \"is_correct\": is_correct\n",
    "                })\n",
    "    \n",
    "    accuracy = correct / max(1, total) * 100\n",
    "    \n",
    "    # 打印前10个和后10个样本\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"前 10 个样本的预测结果对比:\")\n",
    "    print(\"=\"*80)\n",
    "    for i, result in enumerate(all_results[:10], 1):\n",
    "        status = \"✓ 正确\" if result[\"is_correct\"] else \"✗ 错误\"\n",
    "        print(f\"\\n[样本 {i}] {status}\")\n",
    "        print(f\"  问题: {result['question']}\")\n",
    "        print(f\"  真实答案: {result['true_ans_raw']} (归一化: {result['true_ans_norm']})\")\n",
    "        print(f\"  预测答案: {result['pred_raw']} (归一化: {result['pred_norm']})\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"后 10 个样本的预测结果对比:\")\n",
    "    print(\"=\"*80)\n",
    "    for i, result in enumerate(all_results[-10:], len(all_results)-9):\n",
    "        status = \"✓ Right\" if result[\"is_correct\"] else \"✗ Fault\"\n",
    "        print(f\"\\n[Sample {i}] {status}\")\n",
    "        print(f\"  Question: {result['question']}\")\n",
    "        print(f\"  Real answer: {result['true_ans_raw']} (Normalization: {result['true_ans_norm']})\")\n",
    "        print(f\"  Predicted answer: {result['pred_raw']} (Normalization: {result['pred_norm']})\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# 加载训练好的模型\n",
    "model.load_state_dict(torch.load(\"best_blip_close_yesno.pth\", map_location=device))\n",
    "model.to(device)\n",
    "\n",
    "print(\"\\nEvaluate on the test...\")\n",
    "test_accuracy = evaluate_accuracy(model, eval_test_loader, device)\n",
    "print(f\"Test accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dc070c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T06:32:46.205048Z",
     "start_time": "2025-12-19T06:32:46.200173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLIP open 训练集大小: 844，steps/epoch≈211\n",
      "BLIP open 测试集大小: 211\n"
     ]
    }
   ],
   "source": [
    "# ==== 构建 BLIP 用的 open 数据集和 DataLoader（80% 训练 / 20% 测试） ====\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from typing import List, Tuple\n",
    "\n",
    "# 构建一个专门给 BLIP 用的 open 数据集\n",
    "class VQARADBLIPOpenDataset(Dataset):\n",
    "    \"\"\"基于 full_dataset 和 open_idx 列表，返回 (PIL image, question, answer_norm)。\"\"\"\n",
    "\n",
    "    def __init__(self, base_dataset: VQARADBaselineDataset, indices: List[int]):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.indices = indices\n",
    "        self.image_dir = base_dataset.image_dir\n",
    "        self.raw_items = base_dataset.data\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[Image.Image, str, str]:\n",
    "        real_idx = self.indices[idx]\n",
    "        item = self.raw_items[real_idx]\n",
    "\n",
    "        # 读取原始图像（不做 torchvision 的增强，让 BLIP 自己处理）\n",
    "        image_path = self.base_dataset._get_image_path(item)\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        question = item.get(\"question\", \"\")\n",
    "        ans_raw = item.get(\"answer\", \"\")\n",
    "        ans_norm = normalize_answer(ans_raw)\n",
    "\n",
    "        return image, question, ans_norm\n",
    "\n",
    "\n",
    "def blip_open_collate_fn(batch):\n",
    "    \"\"\"将 (image, question, answer) 列表打包成 BLIP 可直接输入的 batch。\"\"\"\n",
    "    images, questions, answers = zip(*batch)\n",
    "\n",
    "    # 使用 Processor 进行图像和文本的联合编码\n",
    "    inputs = processor(\n",
    "        images=list(images),\n",
    "        text=list(questions),\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    # 将答案也转成文本 token，作为 labels\n",
    "    label_tokens = processor.tokenizer(\n",
    "        list(answers),\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    inputs[\"labels\"] = label_tokens.input_ids\n",
    "\n",
    "    return inputs\n",
    "\n",
    "\n",
    "# 基于 Cell 2 中的 open_train_idx / open_test_idx 构建 BLIP 训练 / 测试集\n",
    "blip_open_train_dataset = VQARADBLIPOpenDataset(full_dataset, open_train_idx)\n",
    "blip_open_test_dataset = VQARADBLIPOpenDataset(full_dataset, open_test_idx)\n",
    "\n",
    "blip_open_batch_size = 4  # BLIP 模型较大，batch 不宜太大\n",
    "blip_open_train_loader = DataLoader(\n",
    "    blip_open_train_dataset,\n",
    "    batch_size=blip_open_batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=blip_open_collate_fn,\n",
    ")\n",
    "blip_open_test_loader = DataLoader(\n",
    "    blip_open_test_dataset,\n",
    "    batch_size=blip_open_batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=blip_open_collate_fn,\n",
    ")\n",
    "\n",
    "print(f\"BLIP open 训练集大小: {len(blip_open_train_dataset)}，steps/epoch≈{len(blip_open_train_loader)}\")\n",
    "print(f\"BLIP open 测试集大小: {len(blip_open_test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09d8cdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T06:36:34.098459Z",
     "start_time": "2025-12-19T06:32:46.210173Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:   0%|          | 0/211 [00:00<?, ?it/s]We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "Epoch 1/5: 100%|██████████| 211/211 [00:44<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 5, 平均 loss = 4.2191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 211/211 [00:45<00:00,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 / 5, 平均 loss = 1.5112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 211/211 [00:44<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 / 5, 平均 loss = 0.9712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 211/211 [00:44<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 / 5, 平均 loss = 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 211/211 [00:45<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 / 5, 平均 loss = 0.5926\n",
      "BLIP open 微调完成，模型已保存到: best_blip_open.pth\n"
     ]
    }
   ],
   "source": [
    "# ==== BLIP 微调训练循环（针对 open 数据） ====\n",
    "\n",
    "# 重新加载一个干净的 BLIP 模型（避免受 close 微调的影响）\n",
    "# 如果你想在 close 微调的基础上继续微调 open，可以注释掉下面一行，直接使用已有的 model\n",
    "model_open = BlipForQuestionAnswering.from_pretrained(\"Salesforce/blip-vqa-base\").to(device)\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "num_epochs = 5\n",
    "lr = 5e-5\n",
    "optimizer_open = AdamW(model_open.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model_open.train()\n",
    "    epoch_loss = 0.0\n",
    "    for batch in tqdm(blip_open_train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        # 将 batch 移动到 device 上\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        outputs = model_open(**batch)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        optimizer_open.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_open.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_loss = epoch_loss / max(1, len(blip_open_train_loader))\n",
    "    print(f\"Epoch {epoch+1} / {num_epochs}, 平均 loss = {avg_loss:.4f}\")\n",
    "\n",
    "# 训练完成后保存权重\n",
    "save_path_open = \"best_blip_open.pth\"\n",
    "torch.save(model_open.state_dict(), save_path_open)\n",
    "print(f\"BLIP open 微调完成，模型已保存到: {save_path_open}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302abe8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T06:36:50.476338Z",
     "start_time": "2025-12-19T06:36:44.819720Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 测试集 (open): 100%|██████████| 27/27 [00:05<00:00,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "测试集 (open) 评估结果:\n",
      "  精确匹配准确率: 13.27%  (exact=28, total=211)\n",
      "  语义匹配准确率（宽松）: 28.91%  (semantic=61, total=211)\n",
      "  Overall accuracy：13.27% + 28.91%\n",
      "\n",
      "================================================================================\n",
      "前 10 个样本的预测结果对比:\n",
      "================================================================================\n",
      "\n",
      "[样本 1] ✓ 部分匹配\n",
      "  问题: what pathology is demonstrated?\n",
      "  真实答案: cardiomegaly (归一化: cardiomegaly)\n",
      "  预测答案: cardiomegaly with edema (归一化: cardiomegaly with edema)\n",
      "\n",
      "[样本 2] ✗ 不匹配\n",
      "  问题: What is the pathology?\n",
      "  真实答案: right sided pleural effusion (归一化: right sided pleural effusion)\n",
      "  预测答案: cardiomegaly with edema (归一化: cardiomegaly with edema)\n",
      "\n",
      "[样本 3] ✓ 精确匹配\n",
      "  问题: This image is taken in what plane?\n",
      "  真实答案: axial (归一化: axial)\n",
      "  预测答案: axial (归一化: axial)\n",
      "\n",
      "[样本 4] ✗ 不匹配\n",
      "  问题: Where do we see multiple infarcts in the above image?\n",
      "  真实答案: cerebellum (归一化: cerebellum)\n",
      "  预测答案: left thalamus (归一化: left thalamus)\n",
      "\n",
      "[样本 5] ✗ 不匹配\n",
      "  问题: What kind of image is this?\n",
      "  真实答案: x-ray (归一化: x-ray)\n",
      "  预测答案: ct (归一化: ct)\n",
      "\n",
      "[样本 6] ✓ 精确匹配\n",
      "  问题: Was this MRI taken with or without contrast?\n",
      "  真实答案: with contrast (归一化: with contrast)\n",
      "  预测答案: with contrast (归一化: with contrast)\n",
      "\n",
      "[样本 7] ✓ 部分匹配\n",
      "  问题: What are these opacities anterior to the right kidney?\n",
      "  真实答案: the small intestines (归一化: the small intestines)\n",
      "  预测答案: intestine (归一化: intestine)\n",
      "\n",
      "[样本 8] ✗ 不匹配\n",
      "  问题: What are defining radiological features of the small bowel?\n",
      "  真实答案: not sure (归一化: not sure)\n",
      "  预测答案: air (归一化: air)\n",
      "\n",
      "[样本 9] ✓ 部分匹配\n",
      "  问题: Which lobe is the lesion in?\n",
      "  真实答案: left parietal lobe (归一化: left parietal lobe)\n",
      "  预测答案: upper left lobe (归一化: upper left lobe)\n",
      "\n",
      "[样本 10] ✗ 不匹配\n",
      "  问题: Where is the mass?\n",
      "  真实答案: left rectus abdominus (归一化: left rectus abdominus)\n",
      "  预测答案: suprasellar (归一化: suprasellar)\n",
      "\n",
      "================================================================================\n",
      "后 10 个样本的预测结果对比:\n",
      "================================================================================\n",
      "\n",
      "[样本 202] ✗ 不匹配\n",
      "  问题: Which side of the image is the aortic arch visualized?\n",
      "  真实答案: right (归一化: right)\n",
      "  预测答案: left (归一化: left)\n",
      "\n",
      "[样本 203] ✗ 不匹配\n",
      "  问题: Where is the free-air seen in this image?\n",
      "  真实答案: adjacent to the appendix (归一化: adjacent to the appendix)\n",
      "  预测答案: left thalamus (归一化: left thalamus)\n",
      "\n",
      "[样本 204] ✗ 不匹配\n",
      "  问题: Why is the pancreas abnormal?\n",
      "  真实答案: enlarged (归一化: enlarged)\n",
      "  预测答案: fatty in (归一化: fatty in)\n",
      "\n",
      "[样本 205] ✓ 精确匹配\n",
      "  问题: Which lung is clearer?\n",
      "  真实答案: left (归一化: left)\n",
      "  预测答案: left (归一化: left)\n",
      "\n",
      "[样本 206] ✗ 不匹配\n",
      "  问题: Where is the nodule?\n",
      "  真实答案: below the 7th rib in the right lung (归一化: below the 7th rib in the right lung)\n",
      "  预测答案: mid left subcl vein (归一化: mid left subcl vein)\n",
      "\n",
      "[样本 207] ✗ 不匹配\n",
      "  问题: What organ is enlarged?\n",
      "  真实答案: pancreas (归一化: pancreas)\n",
      "  预测答案: spleen (归一化: spleen)\n",
      "\n",
      "[样本 208] ✗ 不匹配\n",
      "  问题: Describe the lesions in the right kidney?\n",
      "  真实答案: cystic lesions (归一化: cystic lesions)\n",
      "  预测答案: well - circumscribed (归一化: well - circumscribed)\n",
      "\n",
      "[样本 209] ✗ 不匹配\n",
      "  问题: Where is obstruction present, if any?\n",
      "  真实答案: proximal aspect of the appendix (归一化: proximal aspect of the appendix)\n",
      "  预测答案: right subclavian vein (归一化: right subclavian vein)\n",
      "\n",
      "[样本 210] ✗ 不匹配\n",
      "  问题: What caused the lesion?\n",
      "  真实答案: metastasis (归一化: metastasis)\n",
      "  预测答案: ring - enhancing lesion (归一化: ring - enhancing lesion)\n",
      "\n",
      "[样本 211] ✗ 不匹配\n",
      "  问题: What part of the body is being imaged here?\n",
      "  真实答案: abdomen (归一化: abdomen)\n",
      "  预测答案: brain (归一化: brain)\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==== 在 open 子集上评估 BLIP 准确率（使用宽松的语义匹配） ====\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "\n",
    "def eval_open_collate_fn(batch):\n",
    "    images, questions, answers = zip(*batch)\n",
    "    return list(images), list(questions), list(answers)\n",
    "\n",
    "eval_open_test_loader = DataLoader(\n",
    "    blip_open_test_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    collate_fn=eval_open_collate_fn,\n",
    ")\n",
    "\n",
    "def is_semantically_similar_open(pred: str, gt: str) -> bool:\n",
    "    \"\"\"\n",
    "    宽松的语义相似度判断函数（用于open数据）\n",
    "    只要预测答案和真实答案在语义上相似，就返回True\n",
    "    \"\"\"\n",
    "    pred = pred.lower().strip()\n",
    "    gt = gt.lower().strip()\n",
    "    \n",
    "    # 1. 完全匹配\n",
    "    if pred == gt:\n",
    "        return True\n",
    "    \n",
    "    # 2. 去除标点符号后比较\n",
    "    pred_clean = re.sub(r'[^\\w\\s]', '', pred)\n",
    "    gt_clean = re.sub(r'[^\\w\\s]', '', gt)\n",
    "    if pred_clean == gt_clean:\n",
    "        return True\n",
    "    \n",
    "    # 3. 一方包含另一方（子串匹配）\n",
    "    if gt in pred or pred in gt:\n",
    "        return True\n",
    "    \n",
    "    # 4. 提取关键词进行比较（单词级别）\n",
    "    pred_words = set(re.findall(r'\\b\\w+\\b', pred))\n",
    "    gt_words = set(re.findall(r'\\b\\w+\\b', gt))\n",
    "    \n",
    "    # 移除停用词\n",
    "    stop_words = {'the', 'a', 'an', 'is', 'are', 'was', 'were', 'this', 'that', 'these', 'those', 'of', 'in', 'on', 'at', 'to', 'for'}\n",
    "    pred_words = pred_words - stop_words\n",
    "    gt_words = gt_words - stop_words\n",
    "    \n",
    "    # 计算单词重叠度\n",
    "    if len(gt_words) > 0:\n",
    "        overlap_ratio = len(pred_words & gt_words) / len(gt_words)\n",
    "        # 如果重叠度超过50%，认为语义相似\n",
    "        if overlap_ratio >= 0.5:\n",
    "            return True\n",
    "    \n",
    "    # 5. 处理常见的同义词和变体\n",
    "    synonyms = {\n",
    "        'x-ray': ['xray', 'x ray', 'chest xray', 'chest x-ray', 'xray image', 'radiograph'],\n",
    "        'xray': ['x-ray', 'x ray', 'chest xray', 'chest x-ray'],\n",
    "        'ct': ['ct scan', 'computed tomography'],\n",
    "        'mri': ['magnetic resonance imaging'],\n",
    "        'intestines': ['small intestines', 'bowel', 'small bowel', 'intestine'],\n",
    "        'left': ['lt', 'left side'],\n",
    "        'right': ['rt', 'right side'],\n",
    "        'lobe': ['lobes'],\n",
    "        'parietal': ['parietal lobe'],\n",
    "        'frontal': ['frontal lobe'],\n",
    "        'temporal': ['temporal lobe'],\n",
    "        'occipital': ['occipital lobe'],\n",
    "    }\n",
    "    \n",
    "    # 检查同义词\n",
    "    for key, variants in synonyms.items():\n",
    "        if key in gt and any(v in pred for v in variants):\n",
    "            return True\n",
    "        if key in pred and any(v in gt for v in variants):\n",
    "            return True\n",
    "    \n",
    "    # 6. 处理数字和单位（如 \"5cm\" vs \"5 cm\"）\n",
    "    pred_nums = set(re.findall(r'\\d+', pred))\n",
    "    gt_nums = set(re.findall(r'\\d+', gt))\n",
    "    if pred_nums == gt_nums and len(pred_nums) > 0:\n",
    "        # 如果数字相同，且其他单词有重叠，认为相似\n",
    "        pred_non_num_words = set(re.findall(r'\\b[a-z]+\\b', pred))\n",
    "        gt_non_num_words = set(re.findall(r'\\b[a-z]+\\b', gt))\n",
    "        if len(pred_non_num_words & gt_non_num_words) > 0:\n",
    "            return True\n",
    "    \n",
    "    # 7. 处理位置描述（如 \"left parietal lobe\" vs \"parietal lobe\"）\n",
    "    # 如果一方是另一方的子集且包含主要关键词，认为相似\n",
    "    if len(gt_words) > 0 and len(pred_words) > 0:\n",
    "        # 检查主要关键词是否都在\n",
    "        important_words = gt_words - {'left', 'right', 'upper', 'lower', 'anterior', 'posterior', 'side'}\n",
    "        if len(important_words) > 0 and important_words.issubset(pred_words):\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "model_open.eval()\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_open_accuracy(eval_loader, dataset_name):\n",
    "    exact_match = 0  # 完全匹配\n",
    "    partial_match = 0  # 部分匹配（预测答案包含真实答案的关键词）\n",
    "    total = 0\n",
    "    # 存储所有结果用于打印\n",
    "    all_results = []\n",
    "\n",
    "    for images, questions, answers in tqdm(eval_loader, desc=f\"Evaluating {dataset_name}\"):\n",
    "        inputs = processor(\n",
    "            images=list(images),\n",
    "            text=list(questions),\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "        ).to(device)\n",
    "\n",
    "        # 生成答案文本（open 问题答案可能较长，增加 max_new_tokens）\n",
    "        generated_ids = model_open.generate(**inputs, max_new_tokens=20)\n",
    "        preds = processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "\n",
    "        for pred_raw, gt_raw, question in zip(preds, answers, questions):\n",
    "            pred_norm = normalize_answer(pred_raw).lower()\n",
    "            gt_norm = normalize_answer(gt_raw).lower()\n",
    "\n",
    "            # 使用宽松的语义匹配\n",
    "            is_exact = (pred_norm == gt_norm)\n",
    "            is_semantic_match = is_semantically_similar_open(pred_norm, gt_norm)\n",
    "            \n",
    "            if is_exact:\n",
    "                exact_match += 1\n",
    "                partial_match += 1\n",
    "            elif is_semantic_match:\n",
    "                partial_match += 1\n",
    "\n",
    "            total += 1\n",
    "            \n",
    "            # 保存结果\n",
    "            all_results.append({\n",
    "                \"question\": question,\n",
    "                \"pred_raw\": pred_raw,\n",
    "                \"pred_norm\": pred_norm,\n",
    "                \"true_ans_raw\": gt_raw,\n",
    "                \"true_ans_norm\": gt_norm,\n",
    "                \"is_exact\": is_exact,\n",
    "                \"is_partial\": is_semantic_match\n",
    "            })\n",
    "\n",
    "    exact_acc = exact_match / max(1, total)\n",
    "    partial_acc = partial_match / max(1, total)\n",
    "\n",
    "    print(f\"\\n{dataset_name} 评估结果:\")\n",
    "    print(f\"  精确匹配准确率: {exact_acc*100:.2f}%  (exact={exact_match}, total={total})\")\n",
    "    print(f\"  语义匹配准确率（宽松）: {partial_acc*100:.2f}%  (semantic={partial_match}, total={total})\")\n",
    "    print(f\"  Overall accuracy：{exact_acc*100:.2f}% + {partial_acc*100:.2f}%\")\n",
    "    # 打印前10个和后10个样本\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"前 10 个样本的预测结果对比:\")\n",
    "    print(\"=\"*80)\n",
    "    for i, result in enumerate(all_results[:10], 1):\n",
    "        exact_status = \"✓ 精确匹配\" if result[\"is_exact\"] else (\"✓ 部分匹配\" if result[\"is_partial\"] else \"✗ 不匹配\")\n",
    "        print(f\"\\n[样本 {i}] {exact_status}\")\n",
    "        print(f\"  问题: {result['question']}\")\n",
    "        print(f\"  真实答案: {result['true_ans_raw']} (归一化: {result['true_ans_norm']})\")\n",
    "        print(f\"  预测答案: {result['pred_raw']} (归一化: {result['pred_norm']})\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"后 10 个样本的预测结果对比:\")\n",
    "    print(\"=\"*80)\n",
    "    for i, result in enumerate(all_results[-10:], len(all_results)-9):\n",
    "        exact_status = \"✓ 精确匹配\" if result[\"is_exact\"] else (\"✓ 部分匹配\" if result[\"is_partial\"] else \"✗ 不匹配\")\n",
    "        print(f\"\\n[样本 {i}] {exact_status}\")\n",
    "        print(f\"  问题: {result['question']}\")\n",
    "        print(f\"  真实答案: {result['true_ans_raw']} (归一化: {result['true_ans_norm']})\")\n",
    "        print(f\"  预测答案: {result['pred_raw']} (归一化: {result['pred_norm']})\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "\n",
    "model_open.eval()\n",
    "eval_open_accuracy(eval_open_test_loader, \"测试集 (open)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9720fbeaa0590539",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T06:36:39.383810Z",
     "start_time": "2025-12-19T06:36:39.381905Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
